{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyukiNakata/Attention-Seq2Seq/blob/main/Attention_alpha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLp4luhzWiz2"
      },
      "source": [
        "# Attention Seq2seqによる日付変換\n",
        "\n",
        "---\n",
        "\n",
        "## Google ColabでGoogleドライブをマウントする\n",
        "* 以下のコードを実行するとURLが出てくるので，クリック\n",
        "* Googleアカウントに許可を求めたらcodeが出るのでコピー\n",
        "* コピーしたcodeを[空白]にペースト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9INjbE-gW7IP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEiL-x2K0Yx9"
      },
      "source": [
        "# Attention Seq2seq\n",
        "Attention機構は，機械翻訳や文章生成，質問応答など幅広いタスクで応用できる．本セクションでは日付変換，つまり(曜日，日付，年数)を(年数-月-日)に変換させるAttention Seq2seqで解く．\n",
        "\n",
        "<img src=\"https://github.com/himidev/Lecture/blob/main/13_rnn/05_Attention/Atten_Seq2seq.png?raw=true\" width = 100%>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBpeoftq8TQN"
      },
      "source": [
        "#データ準備\n",
        "日付変換をするために， date.txtを学習用と評価用に分割するのと，必要に応じてデータを整理します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oizofu2XxBaG"
      },
      "outputs": [],
      "source": [
        "# データを予めDL\n",
        "!wget -q \"https://drive.google.com/uc?export=download&id=1FKO72lVQ-yNpktQLvj93R2eE9AZJgbLs\" -O date.txt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# 事前にGoogle Driveをマウントして以下の場所にdate.txtを格納しておきます\n",
        "file_path = \"./date.txt\"\n",
        "\n",
        "input_date = [] # 変換前の日付データ\n",
        "output_date = [] # 変換後の日付データ\n",
        "\n",
        "# date.txtを1行ずつ読み込んで変換前と変換後に分割して、inputとoutputで分ける\n",
        "with open(file_path, \"r\") as f:\n",
        "  date_list = f.readlines()\n",
        "  for date in date_list:\n",
        "    date = date[:-1]\n",
        "    input_date.append(date.split(\"_\")[0])\n",
        "    output_date.append(\"_\" + date.split(\"_\")[1])\n",
        "\n",
        "# inputとoutputの系列の長さを取得\n",
        "# すべて長さが同じなので、0番目の要素でlenを取ってます\n",
        "input_len = len(input_date[0]) # 29\n",
        "output_len = len(output_date[0]) # 10\n",
        "\n",
        "# date.txtで登場するすべての文字にIDを割り当てる\n",
        "char2id = {}\n",
        "for input_chars, output_chars in zip(input_date, output_date):\n",
        "  for c in input_chars:\n",
        "    if not c in char2id:\n",
        "      char2id[c] = len(char2id)\n",
        "  for c in output_chars:\n",
        "    if not c in char2id:\n",
        "      char2id[c] = len(char2id)\n",
        "\n",
        "input_data = [] # ID化された変換前日付データ\n",
        "output_data = [] # ID化された変換後日付データ\n",
        "for input_chars, output_chars in zip(input_date, output_date):\n",
        "  if len([char2id[c] for c in output_chars]) != 11:\n",
        "    char2id_ = [char2id[c] for c in output_chars]\n",
        "    char0list = [0 for i in range(11-len([char2id[c] for c in output_chars]))]\n",
        "    char2id_.extend(char0list)\n",
        "    output_data.append(char2id_)\n",
        "  else:\n",
        "    output_data.append([char2id[c] for c in output_chars])\n",
        "  input_data.append([char2id[c] for c in input_chars])\n",
        "# 7:3でtrainとtestに分ける\n",
        "train_x, test_x, train_y, test_y = train_test_split(input_data, output_data, train_size= 0.7)\n",
        "\n",
        "# データをバッチ化するための関数を定義\n",
        "def train2batch(input_data, output_data, batch_size=100):\n",
        "    input_batch = []\n",
        "    output_batch = []\n",
        "    input_shuffle, output_shuffle = shuffle(input_data, output_data)\n",
        "    for i in range(0, len(input_data), batch_size):\n",
        "      input_batch.append(input_shuffle[i:i+batch_size])\n",
        "      output_batch.append(output_shuffle[i:i+batch_size])\n",
        "    return input_batch, output_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jajTAlji8jLy"
      },
      "source": [
        "###エンコーダ・デコーダの作成\n",
        "基本的な構造は前セクションのエンコーダ・デコーダ構造と同様である．ただし，エンコーダは各時刻の出力値を保持しておく．デコーダでは，保持したエンコーダの出力値とデコーダの出力値で内積計算する．この内積計算によって，各時刻のエンコーダの出力値に重み付けすることができる．これにより，どの時刻のエンコーダの出力に着目したかをデコーダ側が自動で決定することができる．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4opavYMyl5k"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# 諸々のパラメータなど\n",
        "embedding_dim = 200\n",
        "hidden_dim = 128\n",
        "BATCH_NUM = 100\n",
        "learning_rate = 0.001\n",
        "vocab_size = len(char2id)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Encoderクラス\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=char2id[\" \"])\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        embedding = self.word_embeddings(sequence)\n",
        "        # hsが各系列のGRUの隠れ層のベクトル\n",
        "        # Attentionされる要素\n",
        "        hs, h = self.gru(embedding)\n",
        "        return hs, h\n",
        "\n",
        "# Attention Decoderクラス\n",
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size):\n",
        "        super(AttentionDecoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=char2id[\" \"])\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "        # hidden_dim*2としているのは、各系列のGRUの隠れ層とAttention層で計算したコンテキストベクトルをtorch.catでつなぎ合わせることで長さが２倍になるため\n",
        "        self.hidden2linear = nn.Linear(hidden_dim * 2, vocab_size)\n",
        "        # 列方向を確率変換したいのでdim=1\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, sequence, hs, h):\n",
        "        embedding = self.word_embeddings(sequence)\n",
        "        output, state = self.gru(embedding, h)\n",
        "\n",
        "        t_output = torch.transpose(output, 1, 2)\n",
        "        s = torch.bmm(hs, t_output)\n",
        "        attention_weight = self.softmax(s)\n",
        "        c = torch.zeros(self.batch_size, 1, self.hidden_dim, device=device)\n",
        "\n",
        "        # Attention weight\n",
        "        for i in range(attention_weight.size()[2]):\n",
        "          unsq_weight = attention_weight[:,:,i].unsqueeze(2)\n",
        "          weighted_hs = hs * unsq_weight\n",
        "          weight_sum = torch.sum(weighted_hs, axis=1).unsqueeze(1)\n",
        "          c = torch.cat([c, weight_sum], dim=1)\n",
        "        c = c[:,1:,:]\n",
        "        output = torch.cat([output, c], dim=2)\n",
        "        output = self.hidden2linear(output)\n",
        "        return output, state, attention_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayrd8ydF85eO"
      },
      "source": [
        "#モデル定義，損失関数，最適化手法\n",
        "EncoderとAttentionDecoderに各パラメータを引数として入れます．損失関数にはCrossEntropyLossを用います．pytorchのCrossEntropyLossには内部にSoftmax関数を持つため，ネットワークの出力後にSoftmax関数を割り当てる必要はありません．最適化手法にはAdamを使用します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgudmNZCzFsi"
      },
      "outputs": [],
      "source": [
        "encoder = Encoder(vocab_size, embedding_dim, hidden_dim).to(device)\n",
        "attn_decoder = AttentionDecoder(vocab_size, embedding_dim, hidden_dim, BATCH_NUM).to(device)\n",
        "\n",
        "# 損失関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "attn_decoder_optimizer = optim.Adam(attn_decoder.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK-tRO9V8-kq"
      },
      "source": [
        "#学習\n",
        "* lossが0.1を下回ったら終了とします"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj6TyDySzH0y"
      },
      "outputs": [],
      "source": [
        "BATCH_NUM=100\n",
        "EPOCH_NUM = 100\n",
        "\n",
        "all_losses = []\n",
        "print(\"training ...\")\n",
        "for epoch in range(1, EPOCH_NUM+1):\n",
        "    epoch_loss = 0\n",
        "    # データをミニバッチに分ける\n",
        "    input_batch, output_batch = train2batch(train_x, train_y, batch_size=BATCH_NUM)\n",
        "    for i in range(len(input_batch)):\n",
        "\n",
        "        # 勾配の初期化\n",
        "        encoder_optimizer.zero_grad()\n",
        "        attn_decoder_optimizer.zero_grad()\n",
        "\n",
        "        # データをテンソルに変換\n",
        "        input_tensor = torch.tensor(input_batch[i], device=device)\n",
        "        output_tensor = torch.tensor(output_batch[i], device=device)\n",
        "\n",
        "        # Encoderの順伝搬\n",
        "        hs, h = encoder(input_tensor)\n",
        "\n",
        "        # Attention Decoderのインプット\n",
        "        source = output_tensor[:, :-1]\n",
        "\n",
        "        # Attention Decoderの正解データ\n",
        "        target = output_tensor[:, 1:]\n",
        "\n",
        "        loss = 0\n",
        "        decoder_output, _, attention_weight= attn_decoder(source, hs, h)\n",
        "        for j in range(decoder_output.size()[1]):\n",
        "            loss += criterion(decoder_output[:, j, :], target[:, j])\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # 誤差逆伝播\n",
        "        loss.backward()\n",
        "\n",
        "        # パラメータ更新\n",
        "        encoder_optimizer.step()\n",
        "        attn_decoder_optimizer.step()\n",
        "\n",
        "    # 損失を表示\n",
        "    print(\"Epoch %d: %.2f\" % (epoch, epoch_loss))\n",
        "    all_losses.append(epoch_loss)\n",
        "    if epoch_loss < 0.1: break\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU8qHKsX9Bhv"
      },
      "source": [
        "#学習推移の可視化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeCN_11nzK4K"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(all_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltTCODki9EFG"
      },
      "source": [
        "#評価\n",
        "表は入力，教師，デコーダの予測出力，正答率を表す"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QerAFLTw0c5r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Decoderのアウトプットのテンソルから要素が最大のインデックスを返す。つまり生成文字を意味します\n",
        "def get_max_index(decoder_output):\n",
        "  results = []\n",
        "  for h in decoder_output:\n",
        "    results.append(torch.argmax(h))\n",
        "  return torch.tensor(results, device=device).view(BATCH_NUM, 1)\n",
        "\n",
        "# 評価用データ\n",
        "test_input_batch, test_output_batch = train2batch(test_x, test_y)\n",
        "input_tensor = torch.tensor(test_input_batch, device=device)\n",
        "\n",
        "predicts = []\n",
        "for i in range(len(test_input_batch)):\n",
        "  with torch.no_grad():\n",
        "    hs, encoder_state = encoder(input_tensor[i])\n",
        "\n",
        "    # Decoderにはまず文字列生成開始を表す\"_\"をインプットにするので、\"_\"のtensorをバッチサイズ分作成\n",
        "    start_char_batch = [[char2id[\"_\"]] for _ in range(BATCH_NUM)]\n",
        "    decoder_input_tensor = torch.tensor(start_char_batch, device=device)\n",
        "\n",
        "    decoder_hidden = encoder_state\n",
        "    batch_tmp = torch.zeros(100,1, dtype=torch.long, device=device)\n",
        "    for _ in range(output_len - 1):\n",
        "      decoder_output, decoder_hidden, _ = attn_decoder(decoder_input_tensor, hs, decoder_hidden)\n",
        "      # 予測文字を取得しつつ、そのまま次のdecoderのインプットとなる\n",
        "      decoder_input_tensor = get_max_index(decoder_output.squeeze())\n",
        "      batch_tmp = torch.cat([batch_tmp, decoder_input_tensor], dim=1)\n",
        "    predicts.append(batch_tmp[:,1:])\n",
        "\n",
        "\n",
        "# 予測結果を見る際にIDのままだと可読性が悪いので、もとの文字列に復元するためのID→文字列に変換する辞書を定義\n",
        "id2char = {}\n",
        "for k, v in char2id.items():\n",
        "  id2char[v] = k\n",
        "\n",
        "row = []\n",
        "for i in range(len(test_input_batch)):\n",
        "  batch_input = test_input_batch[i]\n",
        "  batch_output = test_output_batch[i]\n",
        "  batch_predict = predicts[i]\n",
        "  for inp, output, predict in zip(batch_input, batch_output, batch_predict):\n",
        "    x = [id2char[idx] for idx in inp]\n",
        "    y = [id2char[idx] for idx in output[1:]]\n",
        "    p = [id2char[idx.item()] for idx in predict]\n",
        "\n",
        "    x_str = \"\".join(x)\n",
        "    y_str = \"\".join(y)\n",
        "    p_str = \"\".join(p)\n",
        "\n",
        "    judge = \"O\" if y_str == p_str else \"X\"\n",
        "    row.append([x_str, y_str, p_str, judge])\n",
        "predict_df = pd.DataFrame(row, columns=[\"input\", \"answer\", \"predict\", \"judge\"])\n",
        "predict_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wncNSOdR6HEB"
      },
      "outputs": [],
      "source": [
        "print(len(predict_df.query('judge == \"O\"')) / len(predict_df))\n",
        "\n",
        "predict_df.query('judge == \"X\"').head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtvV9wek9Gl0"
      },
      "source": [
        "# Attentionの可視化\n",
        "* 横軸がEncoderの入力，縦軸が生成文字を表している\n",
        "* 生成文字を１文字ずつ見たとき、左に並んでいるボックスの色が一番明るいところの文字が一番attentionして生成された文字を表している"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auIrXH416KqQ"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "input_batch, output_batch = train2batch(test_x, test_y, batch_size=BATCH_NUM)\n",
        "input_minibatch, output_minibatch = input_batch[0], output_batch[0]\n",
        "\n",
        "with torch.no_grad():\n",
        "  # データをテンソルに変換\n",
        "  input_tensor = torch.tensor(input_minibatch, device=device)\n",
        "  output_tensor = torch.tensor(output_minibatch, device=device)\n",
        "  hs, h = encoder(input_tensor)\n",
        "  source = output_tensor[:, :-1]\n",
        "  decoder_output, _, attention_weight= attn_decoder(source, hs, h)\n",
        "\n",
        "\n",
        "for i in range(3):\n",
        "  with torch.no_grad():\n",
        "    df = pd.DataFrame(data=torch.transpose(attention_weight[i], 0, 1).cpu().numpy(),\n",
        "                      columns=[id2char[idx.item()] for idx in input_tensor[i]],\n",
        "                      index=[id2char[idx.item()] for idx in output_tensor[i][1:]])\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.heatmap(df, xticklabels = 1, yticklabels = 1, square=True, linewidths=.3,cbar_kws = dict(use_gridspec=False,location=\"top\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RLwALW8bo18"
      },
      "source": [
        "参考サイト: https://qiita.com/m__k/items/646044788c5f94eadc8d"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}